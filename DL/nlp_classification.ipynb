{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'],\n",
       "        num_rows: 43410\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'],\n",
       "        num_rows: 5426\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "data = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": \"data/train.csv\", \"validation\": \"data/valid.csv\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-base\")\n",
    "max_len = 8\n",
    "\n",
    "data = data.map(lambda examples: tokenizer(examples[\"text\"],\n",
    "                                           truncation=True,\n",
    "                                           add_special_tokens=True,\n",
    "                                           max_length=max_len,\n",
    "                                           padding=\"max_length\"), batched=True)\n",
    "\n",
    "def one_hot_to_list(example):\n",
    "    emotions = []\n",
    "    for emotion in labels:\n",
    "        emotions.append(example[emotion])\n",
    "    example[\"one_hot_labels\"] = emotions\n",
    "\n",
    "    return example\n",
    "\n",
    "data = data.map(one_hot_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AutoTokenizer`:  `Универсальный` класс для работы с различными токенизаторами в библиотеке Hugging Face\n",
    "\n",
    "- `from_pretrained`(\"ai-forever/ruBert-base\"): Загружает предобученный токенизатор, совместимый с моделью ruBert-base\n",
    "\n",
    "- `max_len`: Максимальная длина последовательности токенов. \n",
    "    - `truncation`: Тексты, содержащие больше токенов, будут `обрезаны`. \n",
    "    - `padding`=\"max_length\": Короткие тексты будут дополнены `паддингом`(нулями)\n",
    "- `add_special_tokens`: Добавляет специальные токены `[CLS]` (в начало) и `[SEP]` (в конец)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 4137, 29093, 25985, 179, 736, 780, 102]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['train'][0]['input_ids'])\n",
    "display(data['train'][0]['attention_mask'])\n",
    "display(data['train'][0]['token_type_ids'])\n",
    "display(data['train'][0]['one_hot_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_ids`: `индексы` токенов, которые берутся из словаря `токенизатора` для подачи в модель\n",
    "\n",
    "- `attention_mask`: формируется токенизатором автоматически и указывает, какие токены в последовательности являются значимыми (1), а какие были добавлены для заполнения (padding, 0)\n",
    "- `token_type_ids`: используются для указания модели, к какому предложению (или части текста) относится каждый токен. Это особенно важно для задач, где вход состоит из двух предложений\n",
    "- `one_hot_labels`: возвращает лейбел как OHE-список\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.dataset[index][\"input_ids\"], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.dataset[index][\"attention_mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(self.dataset[index][\"token_type_ids\"], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.dataset[index][\"one_hot_labels\"], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `EmotionDataset` служит для `преобразования` токенизированного набора данных в формат, пригодный для использования в `PyTorch DataLoader`\n",
    "\n",
    "Возвращает необходимые данные в подходящем формате данных - `torch.long` и `torch.float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(data[\"train\"])\n",
    "valid_dataset = EmotionDataset(data[\"validation\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание `PyTorch DataLoader` из `EmotionDataset`\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, features = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        features = self.dropout(features)\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(\n",
    "    pretrained_model=\"ai-forever/ruBert-base\",\n",
    "    hidden_dim=768,\n",
    "    num_classes=len(labels))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `hidden_dim`: Размерность скрытого слоя\n",
    "\n",
    "- `ids`: Тензор с токенизированными идентификаторами слов\n",
    "- `mask`: Маска внимания, чтобы игнорировать padding токены\n",
    "- `token_type_ids`: Указывает, к какому предложению (в случае двух предложений) принадлежат токены.\n",
    "- `self.bert`: Возвращает два значения: скрытые состояния для всех токенов (`features`) и скрытое состояние CLS-токена (`_`)\n",
    "- `return_dict`=False: указывает, что выход модели должен быть в виде `кортежа`, а не словаря.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `BCEWithLogitsLoss` : Функция потерь, которая объединяет две операции:\n",
    "    - `Сигмоидная` функция для получения логитов в диапазоне [0, 1]\n",
    "    - `Binary Cross-Entropy` (BCE):Вычисляет бинарную кросс-энтропию, которая используется для задач многоклассовой классификации\n",
    "\n",
    "- `weight_decay`:  L2-Регуляризация для предотвращения переобучения.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, dataloader):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for idx, data in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        labels = data[\"labels\"].to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Train loss: {train_loss / len(dataloader)}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.train()`: включает такие функции, как Dropout, которые должны работать только во `время обучени`\n",
    "\n",
    "1. `outputs`: логиты, до применения функции активации\n",
    "2. `loss`: Потери для текущего батча\n",
    "    - `train_loss`: Общие текущие потери\n",
    "3. `loss.backward()`: Вычисление градиентов\n",
    "4. `optimizer.step()`: Обновление параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, dataloader):\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    val_targets, val_outputs = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tqdm(dataloader, desc=\"Valitation\")):\n",
    "            ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            labels = data[\"labels\"].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_targets.extend(labels.cpu().detach().numpy().tolist())\n",
    "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "    print(f'Valid loss: {val_loss / len(dataloader)}')\n",
    "\n",
    "    return val_outputs, val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.eval()`: отключает механизмы, используемые только во время обучения, например Dropout и BatchNorm, что делает предсказания детерминированными\n",
    "\n",
    "- `with torch.no_grad()`: Отключение градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    model = train(model, criterion, optimizer, train_dataloader)\n",
    "    val_outputs, val_targets = validation(model, criterion, valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение и расчет функции потерь для обучения и валидации для текущей эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valitation: 100%|██████████| 85/85 [00:30<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.42584245380233315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.10      0.08      0.09       717\n",
      "     disgust       0.00      0.00      0.00        97\n",
      "        fear       0.03      0.02      0.02       105\n",
      "         joy       0.41      1.00      0.58      2219\n",
      "     sadness       0.07      0.00      0.00       390\n",
      "    surprise       0.10      0.10      0.10       624\n",
      "     neutral       0.33      1.00      0.49      1766\n",
      "\n",
      "   micro avg       0.34      0.69      0.46      5918\n",
      "   macro avg       0.15      0.31      0.18      5918\n",
      "weighted avg       0.28      0.69      0.39      5918\n",
      " samples avg       0.35      0.71      0.46      5918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.3\n",
    "\n",
    "outputs, targets = validation(model, criterion, valid_dataloader)\n",
    "outputs = np.array(outputs) >= THRESHOLD\n",
    "\n",
    "print(metrics.classification_report(targets, outputs, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.array(outputs) >= THRESHOLD`: \n",
    "- массив со значениями `1` , если вероятность больше или равна THRESHOLD\n",
    "- массив со значениями `0` , если вероятность меньше THRESHOLD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
